{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "useful-gender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8375, 1)\n",
      "(8381, 1)\n",
      "(2915, 1)\n",
      "(7972, 1)\n",
      "(6639, 1)\n",
      "(4274, 1)\n",
      "(3784, 1)\n",
      "(2598, 1)\n",
      "(4790, 1)\n",
      "(18000,)\n",
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "#a_food, b_cloth, c_education, d_store, e_lifeservice, \n",
    "#f_cafe, g_accommodation, h_leisure, i_estaet\n",
    "file_list=['a_food','b_cloth','c_education','d_store','e_lifeservice','f_cafe','g_accommodation','h_leisure','i_estate']\n",
    "\n",
    "dir_name=os.getcwd()\n",
    "\n",
    "x_data=[]\n",
    "y_data=[]\n",
    "#extract 2000 sentence data each topic\n",
    "#label value : food-0, cloth-1, education-2,.... estate-8\n",
    "for i in range(0,len(file_list)) :\n",
    "  file_name=dir_name+'/'+file_list[i]+'.csv'\n",
    "  data=pd.read_csv(file_name,header=None)\n",
    "  #print(data.head())\n",
    "  print(data.shape)\n",
    "  #print('..'+data[0][0])\n",
    "  for j in range(0,2000) :\n",
    "    #print(data[0][j])\n",
    "    x_data.append(data[0][j])\n",
    "    y_data.append(i)\n",
    "\n",
    "x_data=np.array(x_data)\n",
    "y_data=np.array(y_data)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tested-trading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16216\n",
      "[[23, 498], [5830, 19, 38, 1, 41, 364, 853, 1], [3663, 415, 46, 5831, 853, 723, 18], [3663, 2076, 946, 671, 193, 1729, 127, 1459], [5832, 5833, 557, 365]]\n",
      "30\n",
      "[[  23  498    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [5830   19   38    1   41  364  853    1    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [3663  415   46 5831  853  723   18    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [3663 2076  946  671  193 1729  127 1459    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [5832 5833  557  365    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "#Pre-processing \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "#Tokenize\n",
    "t=Tokenizer()\n",
    "t.fit_on_texts(x_data)\n",
    "vocab_size=len(t.word_index)+1\n",
    "\n",
    "print(vocab_size) #9976개의 단어가 9천개의 문장에 포함\n",
    "\n",
    "#One-hot encoding\n",
    "x_encoded=t.texts_to_sequences(x_data)\n",
    "print(x_encoded[0:5])\n",
    "max_len=max(len(i) for i in x_encoded) \n",
    "print(max_len) #제일 긴 문장 추출, 패딩에 사용 -- 20\n",
    "\n",
    "#Padding\n",
    "x_encoded=pad_sequences(x_encoded,maxlen=max_len,padding='post')\n",
    "print(x_encoded[0:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collective-shower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('굶주림', 0.7315763235092163), ('갈증', 0.6932728290557861), ('우울증', 0.6545943021774292), ('두통', 0.6426253318786621), ('슬픔', 0.6376044154167175), ('고통', 0.6278344988822937), ('죄책감', 0.6167707443237305), ('고독', 0.6096115708351135), ('통증', 0.6073928475379944), ('가뭄', 0.5912175178527832)]\n",
      "Word2Vec(vocab=30185, size=200, alpha=0.025)\n",
      "(16216, 200)\n",
      "[ 0.87955445  3.51403809 -3.24564695 -0.44390556  1.65877819  2.79138994\n",
      " -2.38859749 -1.69410491 -4.66581869 -1.40278232  0.52966899  2.38166356\n",
      "  1.86097968 -0.2121693   1.29480684  1.340168    1.33980846  0.65593433\n",
      " -3.97182965 -1.87287378 -2.31968427 -0.36057377  1.96739149  2.63297033\n",
      "  3.62644196 -2.02101588 -2.54353046 -3.30448771 -1.73401546  0.10235422\n",
      "  2.16407609 -0.26688221 -1.28560567 -1.07995558 -0.43422294 -1.18709815\n",
      "  2.49914885 -2.92724586  2.0472517   3.16466165 -1.0194726  -0.43097895\n",
      "  0.96997708  2.60468745  0.87658358 -0.95602894  2.89103341 -0.47456264\n",
      "  0.29335284 -3.18679857 -1.16479719  0.40571555 -2.49110079 -0.73088485\n",
      " -0.95157933 -0.47662348 -1.70892262  0.93445814 -2.77651095 -3.0529511\n",
      " -4.91968822  5.06002235 -2.15430808 -1.68313539 -2.39215946  0.76772785\n",
      " -0.87946266  0.609424    2.02752399 -1.54784405  0.45070449  2.58603477\n",
      "  2.59317708 -0.32282627 -2.37348843 -2.20918298  0.22507933  2.93364596\n",
      "  0.45177811 -0.63386536 -4.16563749  0.11986081  1.91843855 -2.64651489\n",
      " -4.42129374  0.86168671 -0.37518859  0.82907426 -1.24126947 -0.47616771\n",
      "  3.4485805  -3.10809827 -1.96047401  1.35669827  0.93814272  1.31368029\n",
      "  1.05071747 -1.99768138 -0.99795443 -0.51403469 -0.32614344  2.72504163\n",
      " -0.83391166 -1.94259477 -1.84902477 -0.45762494 -2.11333776 -1.37368989\n",
      "  0.48921019 -2.3378253  -0.84315044  2.98428369  2.66475773 -2.78355861\n",
      " -2.84693837 -4.31333542 -6.19875479 -0.21488501 -2.13668728 -0.81721467\n",
      " -1.73070264 -0.7771678  -0.570903   -1.26383901 -1.67383051  0.59871942\n",
      "  1.67000842 -3.24008703  1.00734127 -1.22058308 -2.08412504 -0.64214826\n",
      "  0.99690551 -0.26890633 -1.56867731 -1.13106966  0.15695904  0.42776036\n",
      " -1.44155288 -2.27427769  3.46465325  0.57556111  1.7294594   3.63644886\n",
      " -3.61260843  2.32922006 -0.18920034  0.10861432 -1.36970711  2.8147645\n",
      "  1.6807791   0.72796452 -0.84923846  0.5883081   0.48313573 -4.31374216\n",
      "  3.23989058  0.76424021 -0.90233481 -1.46029234  0.29103902 -0.59646332\n",
      " -1.93445075  0.09955439 -2.10077453  1.81703055 -0.21641067 -0.30676064\n",
      " -4.22148848 -0.07612987 -2.76810813 -2.48643517 -0.46263102  3.40009737\n",
      "  0.8513521   3.70463419 -1.47415757  0.90702993  1.83258951 -1.46155858\n",
      " -0.02724529 -1.69391453  2.04618239  0.90828657 -1.715536   -1.49556184\n",
      " -1.48584569 -1.07690144 -0.58771271 -4.35417366 -3.33925486 -1.65874219\n",
      "  0.85608488 -0.16856313  3.3901391   1.06185663  2.12038684  0.54886311\n",
      "  1.3917495   0.06162295]\n",
      "(16216, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-35cf70871181>:11: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if word in kor_word2vec_model :\n",
      "<ipython-input-5-35cf70871181>:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  return kor_word2vec_model[word]\n"
     ]
    }
   ],
   "source": [
    "#Use Pre-trained Embedding Matrix - Word2Vec https://github.com/Kyubyong/wordvectors\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "def get_vector(word) :\n",
    "  if word in kor_word2vec_model :\n",
    "    return kor_word2vec_model[word]\n",
    "  else :\n",
    "    return None\n",
    "\n",
    "kor_word2vec_model = gensim.models.Word2Vec.load(dir_name+'/ko.bin')\n",
    "result = kor_word2vec_model.wv.most_similar(\"배고픔\") #model test\n",
    "print(result) \n",
    "print(kor_word2vec_model) #vector_size=200\n",
    "\n",
    "embedding_dim=200\n",
    "embedding_matrix=np.zeros((vocab_size,embedding_dim))\n",
    "print(np.shape(embedding_matrix))\n",
    "for word, i in t.word_index.items(): \n",
    "  temp=get_vector(word)\n",
    "  if temp is not None :\n",
    "    embedding_matrix[i]=temp; \n",
    "\n",
    "print(embedding_matrix[5])\n",
    "print(embedding_matrix.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "loving-traffic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600 8400\n",
      "(9600, 30) (9600,)\n",
      "(8400, 30) (8400,)\n",
      "[[1931   23   11 3161 1201    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [  11 8504 8505    8 4403 1383    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [ 507  584    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#ID = 0,1,2,3,4,5  OOD = 6,7,8,\n",
    "#Train = id sentence * 0.8 \n",
    "#Test = id sentecne * 0.2 + OOD sentence\n",
    "#for categorycal_cee label데이터 변환\n",
    "categorical_y = to_categorical(y_data, 9)\n",
    "\n",
    "id_data=[]\n",
    "id_label=[]\n",
    "ood_data=[]\n",
    "ood_label=[]\n",
    "for i in range(0,len(x_encoded)) :\n",
    "    if y_data[i] < 6 :\n",
    "        id_data.append(x_encoded[i])\n",
    "        id_label.append(0)\n",
    "    else :\n",
    "        ood_data.append(x_encoded[i])\n",
    "        ood_label.append(1)\n",
    "\n",
    "#id_label=to_categorical(id_label,6)\n",
    "#ood_label=to_categorical(ood_label,3)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(id_data,id_label,\n",
    "                                                    test_size=0.2,stratify=id_label,random_state=0)\n",
    "\n",
    "\n",
    "for i in range(0,len(ood_data)) :\n",
    "    x_test.append(ood_data[i])\n",
    "    y_test.append(ood_label[i])\n",
    "    \n",
    "print(len(x_train),len(x_test))\n",
    "\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)\n",
    "\n",
    "print(x_train[:3])\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "moving-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Model\n",
    "from keras.models import load_model\n",
    "neural_network = load_model('neural_network.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "married-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU 셋팅\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "session=tf.compat.v1.Session(config=config)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3 \n",
    "session=tf.compat.v1.Session(config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "reasonable-exhaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 200)      3243200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 200)      3243200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30, 200)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 200)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30, 400)      0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 400)          961600      concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,448,000\n",
      "Trainable params: 4,204,800\n",
      "Non-trainable params: 3,243,200\n",
      "__________________________________________________________________________________________________\n",
      "======== Inputs ========\n",
      "(9600, 30)\n",
      "\n",
      "======== Outputs of Hidden Layer ========\n",
      "tf.Tensor(\n",
      "[[ 1.8343684e-03 -3.5045267e-04  3.6427914e-03 ...  1.2767616e-04\n",
      "   3.4964175e-03 -3.3838086e-02]\n",
      " [ 1.8343447e-03 -3.5044755e-04  3.6426939e-03 ...  2.9030000e-03\n",
      "   8.1750816e-01 -3.3552852e-03]\n",
      " [ 1.8343503e-03 -3.5045104e-04  3.6427255e-03 ...  2.0205538e-01\n",
      "  -1.1198199e-01  3.3597970e-01]\n",
      " [ 1.8345152e-03 -3.5048908e-04  3.6432338e-03 ... -5.6707874e-02\n",
      "  -1.8111055e-01  2.5643238e-01]\n",
      " [ 1.8344966e-03 -3.5049403e-04  3.6431695e-03 ...  6.0943416e-03\n",
      "   6.3639316e-03 -7.6553684e-01]], shape=(5, 400), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Sentence Embedding의 last hidden layer 가져오기\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "sentence_embedding_layer = Model(inputs=neural_network.input, outputs=neural_network.layers[-3].output)\n",
    "x_train_embedding = sentence_embedding_layer(x_train)\n",
    "x_test_embedding = sentence_embedding_layer(x_test)\n",
    "sentence_embedding_layer.summary()\n",
    "utils.plot_model(sentence_embedding_layer)\n",
    "\n",
    "print('======== Inputs ========')\n",
    "print(x_train.shape)\n",
    "\n",
    "print('\\n======== Outputs of Hidden Layer ========')\n",
    "print(x_train_embedding[:5]) #output dim 400 vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "unavailable-silver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 400)               80400     \n",
      "=================================================================\n",
      "Total params: 361,300\n",
      "Trainable params: 361,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Autoencoder \n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "import keras.utils as utils\n",
    "\n",
    "# sentence_embedding_layer.trainable=False\n",
    "# input=neural_network.input\n",
    "# encoded = Dense(400, activation='tanh')(sentence_embedding_layer)\n",
    "# encoded = Dense(100, activation='tanh')(encoded)\n",
    "\n",
    "# decoded = Dense(400, activation='tanh')(decoded)\n",
    "\n",
    "\n",
    "# autoencoder = Model(neural_network.input, decoded)\n",
    "# autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder=Sequential()\n",
    "autoencoder.add(Dense(400,input_dim=400,activation='tanh'))\n",
    "autoencoder.add(Dense(200,activation='tanh'))\n",
    "autoencoder.add(Dense(100,activation='tanh')) \n",
    "autoencoder.add(Dense(200,activation='tanh'))\n",
    "autoencoder.add(Dense(400,activation='tanh'))\n",
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error') #reconstruction error use\n",
    "\n",
    "autoencoder.summary()\n",
    "utils.plot_model(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "better-arlington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.1233 - val_loss: 0.0974\n",
      "Epoch 2/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1220 - val_loss: 0.0962\n",
      "Epoch 3/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1190 - val_loss: 0.0951\n",
      "Epoch 4/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1172 - val_loss: 0.0941\n",
      "Epoch 5/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1167 - val_loss: 0.0931\n",
      "Epoch 6/500\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.1145 - val_loss: 0.0922\n",
      "Epoch 7/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1137 - val_loss: 0.0913\n",
      "Epoch 8/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1122 - val_loss: 0.0906\n",
      "Epoch 9/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1121 - val_loss: 0.0898\n",
      "Epoch 10/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1112 - val_loss: 0.0891\n",
      "Epoch 11/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1100 - val_loss: 0.0885\n",
      "Epoch 12/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1078 - val_loss: 0.0879\n",
      "Epoch 13/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1071 - val_loss: 0.0873\n",
      "Epoch 14/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1068 - val_loss: 0.0867\n",
      "Epoch 15/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1060 - val_loss: 0.0862\n",
      "Epoch 16/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1057 - val_loss: 0.0857\n",
      "Epoch 17/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1049 - val_loss: 0.0853\n",
      "Epoch 18/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1028 - val_loss: 0.0848\n",
      "Epoch 19/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1031 - val_loss: 0.0844\n",
      "Epoch 20/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1020 - val_loss: 0.0840\n",
      "Epoch 21/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1011 - val_loss: 0.0836\n",
      "Epoch 22/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1019 - val_loss: 0.0832\n",
      "Epoch 23/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0994 - val_loss: 0.0829\n",
      "Epoch 24/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0999 - val_loss: 0.0825\n",
      "Epoch 25/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1005 - val_loss: 0.0822\n",
      "Epoch 26/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0993 - val_loss: 0.0819\n",
      "Epoch 27/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0983 - val_loss: 0.0816\n",
      "Epoch 28/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0981 - val_loss: 0.0813\n",
      "Epoch 29/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0974 - val_loss: 0.0810\n",
      "Epoch 30/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0969 - val_loss: 0.0807\n",
      "Epoch 31/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0965 - val_loss: 0.0804\n",
      "Epoch 32/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0953 - val_loss: 0.0802\n",
      "Epoch 33/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0954 - val_loss: 0.0799\n",
      "Epoch 34/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0960 - val_loss: 0.0796\n",
      "Epoch 35/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0953 - val_loss: 0.0794\n",
      "Epoch 36/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0953 - val_loss: 0.0791\n",
      "Epoch 37/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0950 - val_loss: 0.0789\n",
      "Epoch 38/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0944 - val_loss: 0.0787\n",
      "Epoch 39/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0941 - val_loss: 0.0784\n",
      "Epoch 40/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0937 - val_loss: 0.0782\n",
      "Epoch 41/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.0780\n",
      "Epoch 42/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.0778\n",
      "Epoch 43/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.0776\n",
      "Epoch 44/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.0773\n",
      "Epoch 45/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.0771\n",
      "Epoch 46/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.0769\n",
      "Epoch 47/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0916 - val_loss: 0.0767\n",
      "Epoch 48/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0908 - val_loss: 0.0765\n",
      "Epoch 49/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.0763\n",
      "Epoch 50/500\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.0761\n",
      "Epoch 51/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.0760\n",
      "Epoch 52/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0758\n",
      "Epoch 53/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0756\n",
      "Epoch 54/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0897 - val_loss: 0.0754\n",
      "Epoch 55/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0886 - val_loss: 0.0752\n",
      "Epoch 56/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0883 - val_loss: 0.0750\n",
      "Epoch 57/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0887 - val_loss: 0.0748\n",
      "Epoch 58/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0747\n",
      "Epoch 59/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0879 - val_loss: 0.0745\n",
      "Epoch 60/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0874 - val_loss: 0.0743\n",
      "Epoch 61/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0875 - val_loss: 0.0741\n",
      "Epoch 62/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0740\n",
      "Epoch 63/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0871 - val_loss: 0.0738\n",
      "Epoch 64/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0871 - val_loss: 0.0736\n",
      "Epoch 65/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0868 - val_loss: 0.0735\n",
      "Epoch 66/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0861 - val_loss: 0.0733\n",
      "Epoch 67/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0731\n",
      "Epoch 68/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.0730\n",
      "Epoch 69/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0865 - val_loss: 0.0728\n",
      "Epoch 70/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0851 - val_loss: 0.0726\n",
      "Epoch 71/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0725\n",
      "Epoch 72/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0723\n",
      "Epoch 73/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0852 - val_loss: 0.0722\n",
      "Epoch 74/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0852 - val_loss: 0.0720\n",
      "Epoch 75/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.0718\n",
      "Epoch 76/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0835 - val_loss: 0.0717\n",
      "Epoch 77/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0715\n",
      "Epoch 78/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0840 - val_loss: 0.0714\n",
      "Epoch 79/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0835 - val_loss: 0.0712\n",
      "Epoch 80/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0711\n",
      "Epoch 81/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.0709\n",
      "Epoch 82/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0708\n",
      "Epoch 83/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0706\n",
      "Epoch 84/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0705\n",
      "Epoch 85/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0703\n",
      "Epoch 86/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0829 - val_loss: 0.0702\n",
      "Epoch 87/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0816 - val_loss: 0.0700\n",
      "Epoch 88/500\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0817 - val_loss: 0.0699\n",
      "Epoch 89/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0697\n",
      "Epoch 90/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0696\n",
      "Epoch 91/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0694\n",
      "Epoch 92/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0804 - val_loss: 0.0693\n",
      "Epoch 93/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0691\n",
      "Epoch 94/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0690\n",
      "Epoch 95/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0689\n",
      "Epoch 96/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0687\n",
      "Epoch 97/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0686\n",
      "Epoch 98/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0684\n",
      "Epoch 99/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0683\n",
      "Epoch 100/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0791 - val_loss: 0.0681\n",
      "Epoch 101/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0680\n",
      "Epoch 102/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0679\n",
      "Epoch 103/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0677\n",
      "Epoch 104/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0676\n",
      "Epoch 105/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0674\n",
      "Epoch 106/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0673\n",
      "Epoch 107/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0672\n",
      "Epoch 108/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0670\n",
      "Epoch 109/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0669\n",
      "Epoch 110/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.0667\n",
      "Epoch 111/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0666\n",
      "Epoch 112/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.0665\n",
      "Epoch 113/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.0663\n",
      "Epoch 114/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0662\n",
      "Epoch 115/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0661\n",
      "Epoch 116/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0659\n",
      "Epoch 117/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0658\n",
      "Epoch 118/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0657\n",
      "Epoch 119/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.0655\n",
      "Epoch 120/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0654\n",
      "Epoch 121/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0653\n",
      "Epoch 122/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0651\n",
      "Epoch 123/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0650\n",
      "Epoch 124/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0649\n",
      "Epoch 125/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0647\n",
      "Epoch 126/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0646\n",
      "Epoch 127/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0645\n",
      "Epoch 128/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0644\n",
      "Epoch 129/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.0642\n",
      "Epoch 130/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0641\n",
      "Epoch 131/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0640\n",
      "Epoch 132/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0638\n",
      "Epoch 133/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0637\n",
      "Epoch 134/500\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0717 - val_loss: 0.0636\n",
      "Epoch 135/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0635\n",
      "Epoch 136/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0633\n",
      "Epoch 137/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.0632\n",
      "Epoch 138/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0631\n",
      "Epoch 139/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0629\n",
      "Epoch 140/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0628\n",
      "Epoch 141/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.0627\n",
      "Epoch 142/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0626\n",
      "Epoch 143/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0624\n",
      "Epoch 144/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0700 - val_loss: 0.0623\n",
      "Epoch 145/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0622\n",
      "Epoch 146/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0621\n",
      "Epoch 147/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.0620\n",
      "Epoch 148/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.0618\n",
      "Epoch 149/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0617\n",
      "Epoch 150/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0616\n",
      "Epoch 151/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.0615\n",
      "Epoch 152/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.0613\n",
      "Epoch 153/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.0612\n",
      "Epoch 154/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.0611\n",
      "Epoch 155/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0679 - val_loss: 0.0610\n",
      "Epoch 156/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.0609\n",
      "Epoch 157/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0607\n",
      "Epoch 158/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0606\n",
      "Epoch 159/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0605\n",
      "Epoch 160/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.0604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0671 - val_loss: 0.0603\n",
      "Epoch 162/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0602\n",
      "Epoch 163/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0600\n",
      "Epoch 164/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0599\n",
      "Epoch 165/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0668 - val_loss: 0.0598\n",
      "Epoch 166/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0597\n",
      "Epoch 167/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0596\n",
      "Epoch 168/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0595\n",
      "Epoch 169/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.0594\n",
      "Epoch 170/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0657 - val_loss: 0.0592\n",
      "Epoch 171/500\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0656 - val_loss: 0.0591\n",
      "Epoch 172/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0654 - val_loss: 0.0590\n",
      "Epoch 173/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0646 - val_loss: 0.0589\n",
      "Epoch 174/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0588\n",
      "Epoch 175/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0587\n",
      "Epoch 176/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0586\n",
      "Epoch 177/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0585\n",
      "Epoch 178/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0584\n",
      "Epoch 179/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0582\n",
      "Epoch 180/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0581\n",
      "Epoch 181/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0580\n",
      "Epoch 182/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0579\n",
      "Epoch 183/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0578\n",
      "Epoch 184/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0577\n",
      "Epoch 185/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0576\n",
      "Epoch 186/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0630 - val_loss: 0.0575\n",
      "Epoch 187/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0574\n",
      "Epoch 188/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0573\n",
      "Epoch 189/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0572\n",
      "Epoch 190/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.0571\n",
      "Epoch 191/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0570\n",
      "Epoch 192/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0569\n",
      "Epoch 193/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0568\n",
      "Epoch 194/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0566\n",
      "Epoch 195/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0565\n",
      "Epoch 196/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0564\n",
      "Epoch 197/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0563\n",
      "Epoch 198/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0562\n",
      "Epoch 199/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0561\n",
      "Epoch 200/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0560\n",
      "Epoch 201/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0559\n",
      "Epoch 202/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0558\n",
      "Epoch 203/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0557\n",
      "Epoch 204/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0556\n",
      "Epoch 205/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0555\n",
      "Epoch 206/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0554\n",
      "Epoch 207/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0553\n",
      "Epoch 208/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0552\n",
      "Epoch 209/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0552\n",
      "Epoch 210/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0551\n",
      "Epoch 211/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0550\n",
      "Epoch 212/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0549\n",
      "Epoch 213/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0548\n",
      "Epoch 214/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0547\n",
      "Epoch 215/500\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0546\n",
      "Epoch 216/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0545\n",
      "Epoch 217/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0544\n",
      "Epoch 218/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0543\n",
      "Epoch 219/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
      "Epoch 220/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
      "Epoch 221/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
      "Epoch 222/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
      "Epoch 223/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0538\n",
      "Epoch 224/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0538\n",
      "Epoch 225/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0537\n",
      "Epoch 226/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0536\n",
      "Epoch 227/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0535\n",
      "Epoch 228/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0534\n",
      "Epoch 229/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0533\n",
      "Epoch 230/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0532\n",
      "Epoch 231/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0531\n",
      "Epoch 232/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0531\n",
      "Epoch 233/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0530\n",
      "Epoch 234/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.0529\n",
      "Epoch 235/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0528\n",
      "Epoch 236/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0527\n",
      "Epoch 237/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0526\n",
      "Epoch 238/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0526\n",
      "Epoch 239/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0525\n",
      "Epoch 240/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0524\n",
      "Epoch 241/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0523\n",
      "Epoch 242/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0522\n",
      "Epoch 243/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0521\n",
      "Epoch 244/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0521\n",
      "Epoch 245/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0520\n",
      "Epoch 246/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0519\n",
      "Epoch 247/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0518\n",
      "Epoch 248/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0517\n",
      "Epoch 249/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0517\n",
      "Epoch 250/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0516\n",
      "Epoch 251/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0515\n",
      "Epoch 252/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0514\n",
      "Epoch 253/500\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0514\n",
      "Epoch 254/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0513\n",
      "Epoch 255/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0512\n",
      "Epoch 256/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0511\n",
      "Epoch 257/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0511\n",
      "Epoch 258/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0510\n",
      "Epoch 259/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0509\n",
      "Epoch 260/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0508\n",
      "Epoch 261/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0508\n",
      "Epoch 262/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0507\n",
      "Epoch 263/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0506\n",
      "Epoch 264/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0505\n",
      "Epoch 265/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0505\n",
      "Epoch 266/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0504\n",
      "Epoch 267/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0503\n",
      "Epoch 268/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0503\n",
      "Epoch 269/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0502\n",
      "Epoch 270/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0501\n",
      "Epoch 271/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0500\n",
      "Epoch 272/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0500\n",
      "Epoch 273/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.0499\n",
      "Epoch 274/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0498\n",
      "Epoch 275/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0498\n",
      "Epoch 276/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0497\n",
      "Epoch 277/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0496\n",
      "Epoch 278/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0496\n",
      "Epoch 279/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0495\n",
      "Epoch 280/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0494\n",
      "Epoch 281/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0494\n",
      "Epoch 282/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0493\n",
      "Epoch 283/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0493\n",
      "Epoch 284/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0492\n",
      "Epoch 285/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0491\n",
      "Epoch 286/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0491\n",
      "Epoch 287/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0490\n",
      "Epoch 288/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0489\n",
      "Epoch 289/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0489\n",
      "Epoch 290/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0488\n",
      "Epoch 291/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0488\n",
      "Epoch 292/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0490 - val_loss: 0.0487\n",
      "Epoch 293/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0485 - val_loss: 0.0486\n",
      "Epoch 294/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0482 - val_loss: 0.0486\n",
      "Epoch 295/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0485\n",
      "Epoch 296/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.0485\n",
      "Epoch 297/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0487 - val_loss: 0.0484\n",
      "Epoch 298/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0483 - val_loss: 0.0483\n",
      "Epoch 299/500\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0483\n",
      "Epoch 300/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0482 - val_loss: 0.0482\n",
      "Epoch 301/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0480 - val_loss: 0.0482\n",
      "Epoch 302/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0479 - val_loss: 0.0481\n",
      "Epoch 303/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0481 - val_loss: 0.0481\n",
      "Epoch 304/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0479 - val_loss: 0.0480\n",
      "Epoch 305/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0476 - val_loss: 0.0479\n",
      "Epoch 306/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0481 - val_loss: 0.0479\n",
      "Epoch 307/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0482 - val_loss: 0.0478\n",
      "Epoch 308/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0477 - val_loss: 0.0478\n",
      "Epoch 309/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0474 - val_loss: 0.0477\n",
      "Epoch 310/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0476 - val_loss: 0.0477\n",
      "Epoch 311/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0466 - val_loss: 0.0476\n",
      "Epoch 312/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0473 - val_loss: 0.0476\n",
      "Epoch 313/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0475 - val_loss: 0.0475\n",
      "Epoch 314/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0472 - val_loss: 0.0475\n",
      "Epoch 315/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0471 - val_loss: 0.0474\n",
      "Epoch 316/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0469 - val_loss: 0.0473\n",
      "Epoch 317/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0471 - val_loss: 0.0473\n",
      "Epoch 318/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0470 - val_loss: 0.0472\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0466 - val_loss: 0.0472\n",
      "Epoch 320/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0466 - val_loss: 0.0471\n",
      "Epoch 321/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0465 - val_loss: 0.0471\n",
      "Epoch 322/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0469 - val_loss: 0.0470\n",
      "Epoch 323/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0467 - val_loss: 0.0470\n",
      "Epoch 324/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0464 - val_loss: 0.0469\n",
      "Epoch 325/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0463 - val_loss: 0.0469\n",
      "Epoch 326/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0462 - val_loss: 0.0468\n",
      "Epoch 327/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0464 - val_loss: 0.0468\n",
      "Epoch 328/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0461 - val_loss: 0.0468\n",
      "Epoch 329/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0459 - val_loss: 0.0467\n",
      "Epoch 330/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0458 - val_loss: 0.0467\n",
      "Epoch 331/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0457 - val_loss: 0.0466\n",
      "Epoch 332/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0454 - val_loss: 0.0466\n",
      "Epoch 333/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0459 - val_loss: 0.0465\n",
      "Epoch 334/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0456 - val_loss: 0.0465\n",
      "Epoch 335/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0456 - val_loss: 0.0464\n",
      "Epoch 336/500\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0450 - val_loss: 0.0464\n",
      "Epoch 337/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0451 - val_loss: 0.0463\n",
      "Epoch 338/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0458 - val_loss: 0.0463\n",
      "Epoch 339/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0451 - val_loss: 0.0462\n",
      "Epoch 340/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0449 - val_loss: 0.0462\n",
      "Epoch 341/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0450 - val_loss: 0.0462\n",
      "Epoch 342/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0453 - val_loss: 0.0461\n",
      "Epoch 343/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0447 - val_loss: 0.0461\n",
      "Epoch 344/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0446 - val_loss: 0.0460\n",
      "Epoch 345/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0448 - val_loss: 0.0460\n",
      "Epoch 346/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0451 - val_loss: 0.0459\n",
      "Epoch 347/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0447 - val_loss: 0.0459\n",
      "Epoch 348/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0447 - val_loss: 0.0459\n",
      "Epoch 349/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0443 - val_loss: 0.0458\n",
      "Epoch 350/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0446 - val_loss: 0.0458\n",
      "Epoch 351/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0450 - val_loss: 0.0457\n",
      "Epoch 352/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0440 - val_loss: 0.0457\n",
      "Epoch 353/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0442 - val_loss: 0.0457\n",
      "Epoch 354/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0440 - val_loss: 0.0456\n",
      "Epoch 355/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0443 - val_loss: 0.0456\n",
      "Epoch 356/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0445 - val_loss: 0.0455\n",
      "Epoch 357/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.0455\n",
      "Epoch 358/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0440 - val_loss: 0.0455\n",
      "Epoch 359/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0435 - val_loss: 0.0454\n",
      "Epoch 360/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0437 - val_loss: 0.0454\n",
      "Epoch 361/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.0453\n",
      "Epoch 362/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.0453\n",
      "Epoch 363/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0436 - val_loss: 0.0453\n",
      "Epoch 364/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0439 - val_loss: 0.0452\n",
      "Epoch 365/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.0452\n",
      "Epoch 366/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0434 - val_loss: 0.0451\n",
      "Epoch 367/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0432 - val_loss: 0.0451\n",
      "Epoch 368/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0436 - val_loss: 0.0451\n",
      "Epoch 369/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0437 - val_loss: 0.0450\n",
      "Epoch 370/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.0450\n",
      "Epoch 371/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0430 - val_loss: 0.0450\n",
      "Epoch 372/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0432 - val_loss: 0.0449\n",
      "Epoch 373/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0430 - val_loss: 0.0449\n",
      "Epoch 374/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.0449\n",
      "Epoch 375/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0429 - val_loss: 0.0448\n",
      "Epoch 376/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0448\n",
      "Epoch 377/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.0448\n",
      "Epoch 378/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0447\n",
      "Epoch 379/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.0447\n",
      "Epoch 380/500\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0447\n",
      "Epoch 381/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0430 - val_loss: 0.0446\n",
      "Epoch 382/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.0446\n",
      "Epoch 383/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0446\n",
      "Epoch 384/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.0445\n",
      "Epoch 385/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.0445\n",
      "Epoch 386/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0445\n",
      "Epoch 387/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0444\n",
      "Epoch 388/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0444\n",
      "Epoch 389/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.0444\n",
      "Epoch 390/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0443\n",
      "Epoch 391/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0443\n",
      "Epoch 392/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0443\n",
      "Epoch 393/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.0442\n",
      "Epoch 394/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0442\n",
      "Epoch 395/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0442\n",
      "Epoch 396/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0441\n",
      "Epoch 397/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0441\n",
      "Epoch 398/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0441\n",
      "Epoch 399/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0440\n",
      "Epoch 400/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0440\n",
      "Epoch 401/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0440\n",
      "Epoch 402/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0440\n",
      "Epoch 403/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0439\n",
      "Epoch 404/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0439\n",
      "Epoch 405/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0439\n",
      "Epoch 406/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0438\n",
      "Epoch 407/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0438\n",
      "Epoch 408/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0438\n",
      "Epoch 409/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0438\n",
      "Epoch 410/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0437\n",
      "Epoch 411/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0437\n",
      "Epoch 412/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0437\n",
      "Epoch 413/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0436\n",
      "Epoch 414/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0436\n",
      "Epoch 415/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0436\n",
      "Epoch 416/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0436\n",
      "Epoch 417/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0435\n",
      "Epoch 418/500\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0435\n",
      "Epoch 419/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0435\n",
      "Epoch 420/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0435\n",
      "Epoch 421/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0434\n",
      "Epoch 422/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0434\n",
      "Epoch 423/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0434\n",
      "Epoch 424/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0434\n",
      "Epoch 425/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0433\n",
      "Epoch 426/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0433\n",
      "Epoch 427/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0433\n",
      "Epoch 428/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0433\n",
      "Epoch 429/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0432\n",
      "Epoch 430/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0432\n",
      "Epoch 431/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0432\n",
      "Epoch 432/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0432\n",
      "Epoch 433/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0431\n",
      "Epoch 434/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0431\n",
      "Epoch 435/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0431\n",
      "Epoch 436/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0431\n",
      "Epoch 437/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0430\n",
      "Epoch 438/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0430\n",
      "Epoch 439/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0430\n",
      "Epoch 440/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0430\n",
      "Epoch 441/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0429\n",
      "Epoch 442/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0429\n",
      "Epoch 443/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0429\n",
      "Epoch 444/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0429\n",
      "Epoch 445/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0429\n",
      "Epoch 446/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0428\n",
      "Epoch 447/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0428\n",
      "Epoch 448/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0428\n",
      "Epoch 449/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0428\n",
      "Epoch 450/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0427\n",
      "Epoch 451/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0427\n",
      "Epoch 452/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0427\n",
      "Epoch 453/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0427\n",
      "Epoch 454/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0427\n",
      "Epoch 455/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0426\n",
      "Epoch 456/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0426\n",
      "Epoch 457/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0426\n",
      "Epoch 458/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0392 - val_loss: 0.0426\n",
      "Epoch 459/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.0426\n",
      "Epoch 460/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0425\n",
      "Epoch 461/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0425\n",
      "Epoch 462/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.0425\n",
      "Epoch 463/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0425\n",
      "Epoch 464/500\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0395 - val_loss: 0.0425\n",
      "Epoch 465/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0393 - val_loss: 0.0424\n",
      "Epoch 466/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.0424\n",
      "Epoch 467/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0424\n",
      "Epoch 468/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0391 - val_loss: 0.0424\n",
      "Epoch 469/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0424\n",
      "Epoch 470/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.0423\n",
      "Epoch 471/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0423\n",
      "Epoch 472/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0392 - val_loss: 0.0423\n",
      "Epoch 473/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0393 - val_loss: 0.0423\n",
      "Epoch 474/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0391 - val_loss: 0.0423\n",
      "Epoch 475/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0392 - val_loss: 0.0422\n",
      "Epoch 476/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0422\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0393 - val_loss: 0.0422\n",
      "Epoch 478/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0385 - val_loss: 0.0422\n",
      "Epoch 479/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0389 - val_loss: 0.0422\n",
      "Epoch 480/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0389 - val_loss: 0.0422\n",
      "Epoch 481/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0391 - val_loss: 0.0421\n",
      "Epoch 482/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0388 - val_loss: 0.0421\n",
      "Epoch 483/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0386 - val_loss: 0.0421\n",
      "Epoch 484/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.0421\n",
      "Epoch 485/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0389 - val_loss: 0.0421\n",
      "Epoch 486/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0387 - val_loss: 0.0420\n",
      "Epoch 487/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.0420\n",
      "Epoch 488/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0387 - val_loss: 0.0420\n",
      "Epoch 489/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0387 - val_loss: 0.0420\n",
      "Epoch 490/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.0420\n",
      "Epoch 491/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0385 - val_loss: 0.0420\n",
      "Epoch 492/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0388 - val_loss: 0.0419\n",
      "Epoch 493/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0388 - val_loss: 0.0419\n",
      "Epoch 494/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0385 - val_loss: 0.0419\n",
      "Epoch 495/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0385 - val_loss: 0.0419\n",
      "Epoch 496/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0384 - val_loss: 0.0419\n",
      "Epoch 497/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0388 - val_loss: 0.0419\n",
      "Epoch 498/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0387 - val_loss: 0.0418\n",
      "Epoch 499/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0382 - val_loss: 0.0418\n",
      "Epoch 500/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0381 - val_loss: 0.0418\n"
     ]
    }
   ],
   "source": [
    "history=autoencoder.fit(x_train_embedding, x_train_embedding,\n",
    "                epochs=500,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_embedding, x_test_embedding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "brown-beginning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.callbacks.History object at 0x7fd35d1d4e20>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history)\n",
    "plt.plot(history.history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history.history['val_loss'], linewidth=2, label='Valid')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "novel-container",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstruction_error</th>\n",
       "      <th>true_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8400.000000</td>\n",
       "      <td>8400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.041808</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.451781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.004349</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.020523</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.038874</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.059019</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.176504</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reconstruction_error   true_class\n",
       "count           8400.000000  8400.000000\n",
       "mean               0.041808     0.714286\n",
       "std                0.025745     0.451781\n",
       "min                0.004349     0.000000\n",
       "25%                0.020523     0.000000\n",
       "50%                0.038874     1.000000\n",
       "75%                0.059019     1.000000\n",
       "max                0.176504     1.000000"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#오류 분포\n",
    "predictions = autoencoder.predict(x_test_embedding)\n",
    "\n",
    "mse = np.mean(np.power(x_test_embedding - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': y_test})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "taken-restoration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ID sentence 재구성 오류 분포\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "normal_error_df = error_df[(error_df['true_class']== 0) & (error_df['reconstruction_error'] < 10)]\n",
    "_ = ax.hist(normal_error_df.reconstruction_error.values, bins=10)\n",
    "\n",
    "#ID sentence 재구성 오류 분포\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "normal_error_df = error_df[(error_df['true_class']== 1) & (error_df['reconstruction_error'] < 10)]\n",
    "_ = ax.hist(normal_error_df.reconstruction_error.values, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "applied-athens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold :  0.29900000000000004\n",
      "max accuracy :  0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "max_threshold=0\n",
    "max_accuracy=0\n",
    "\n",
    "def predict(model, data, threshold):\n",
    "  reconstructions = model(data)\n",
    "  loss = tf.keras.losses.mae(reconstructions, data)\n",
    "  return tf.math.less(loss, threshold)\n",
    "\n",
    "def print_stats(predictions, labels,threshold):\n",
    "  global max_threshold\n",
    "  global max_accuracy\n",
    "  acc=accuracy_score(labels,preds)\n",
    "  if max_accuracy < acc :\n",
    "        max_threshold=threshold\n",
    "        max_accuracy=acc\n",
    "        \n",
    "  #print(\"Accuracy = {}\".format(accuracy_score(labels, preds)))\n",
    "  #print(\"Precision = {}\".format(precision_score(labels, preds)))\n",
    "  #print(\"Recall = {}\".format(recall_score(labels, preds)))\n",
    "\n",
    "preds = predict(autoencoder, x_test_embedding, threshold)\n",
    "#print('threshold : ',threshold)\n",
    "#print_stats(preds, y_test,threshold)\n",
    "\n",
    "\n",
    "for temp in range(0, 300):\n",
    "    temp=0.1+temp/1000\n",
    "    preds = predict(autoencoder, x_test_embedding, temp)\n",
    "    #print('threshold : ',temp)\n",
    "    print_stats(preds, y_test,temp)\n",
    "\n",
    "print('threshold : ',max_threshold)\n",
    "print('max accuracy : ',max_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
